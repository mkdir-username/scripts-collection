#!/usr/bin/env python3
"""
Simplified Performance Analyzer for SDUI Resolver
–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –±–µ–∑ –≤–Ω–µ—à–Ω–∏—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
"""

import time
import json
import cProfile
import pstats
import io
import tracemalloc
import sys
import gc
from pathlib import Path
from typing import Dict, List, Any, Tuple
from dataclasses import dataclass
from contextlib import contextmanager

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º–æ–º—É —Å–∫—Ä–∏–ø—Ç—É
sys.path.insert(0, str(Path(__file__).parent))

try:
    from sdui_resolver_final import SDUIFinalResolver, ResolveContext, ComponentTracker
except ImportError as e:
    print(f"‚ùå Cannot import sdui-resolver-final.py: {e}")
    print("Make sure the file exists and has correct Python syntax")
    sys.exit(1)

@dataclass
class SimpleMetrics:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    execution_time: float = 0.0
    memory_peak: int = 0
    memory_current: int = 0
    operations_count: int = 0

class SimpleProfiler:
    """–£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫"""

    def __init__(self):
        self.metrics = SimpleMetrics()
        self.start_time = 0
        self.operation_times = {}
        self.call_counts = {}

    @contextmanager
    def measure_operation(self, operation_name: str):
        """–ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –º–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –æ–ø–µ—Ä–∞—Ü–∏–π"""
        start_time = time.perf_counter()

        try:
            yield
        finally:
            duration = time.perf_counter() - start_time

            if operation_name not in self.operation_times:
                self.operation_times[operation_name] = []
                self.call_counts[operation_name] = 0

            self.operation_times[operation_name].append(duration)
            self.call_counts[operation_name] += 1

    def start_profiling(self):
        """–ù–∞—á–∞—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        tracemalloc.start()
        self.start_time = time.perf_counter()
        gc.collect()  # –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è —Å–±–æ—Ä–∫–∞ –º—É—Å–æ—Ä–∞ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞

    def stop_profiling(self):
        """–ó–∞–≤–µ—Ä—à–∏—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        self.metrics.execution_time = time.perf_counter() - self.start_time

        # –ü–∏–∫–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        try:
            current, peak = tracemalloc.get_traced_memory()
            self.metrics.memory_peak = peak
            self.metrics.memory_current = current
            tracemalloc.stop()
        except:
            pass

class SDUIPerformanceAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ SDUI Resolver"""

    def __init__(self, script_path: str):
        self.script_path = Path(script_path)
        self.base_path = self.script_path.parent

    def create_test_schema(self, complexity: str = "simple", size: int = 10) -> Dict:
        """–°–æ–∑–¥–∞—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é —Å—Ö–µ–º—É"""
        if complexity == "simple":
            return {
                "name": "SimpleTestSchema",
                "type": "object",
                "properties": {
                    "id": {"type": "string"},
                    "name": {"type": "string"},
                    "value": {"type": "number"}
                }
            }

        elif complexity == "medium":
            schema = {
                "name": "MediumTestSchema",
                "type": "object",
                "definitions": {}
            }

            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ø–æ—á–∫—É —Å—Å—ã–ª–æ–∫
            for i in range(size):
                schema["definitions"][f"Component{i}"] = {
                    "type": "object",
                    "properties": {
                        "id": {"type": "string"},
                        "data": {"type": "object"},
                        "next": {"$ref": f"#/definitions/Component{(i + 1) % size}"}
                    }
                }

            schema["properties"] = {
                "root": {"$ref": "#/definitions/Component0"}
            }

            return schema

        else:  # complex
            schema = {
                "name": "ComplexTestSchema",
                "type": "object",
                "definitions": {}
            }

            # –°–æ–∑–¥–∞–µ–º —Å–ª–æ–∂–Ω—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É —Å –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–º–∏ —Å—Å—ã–ª–∫–∞–º–∏
            for i in range(size):
                references = []
                for j in range(min(3, size)):
                    ref_target = (i + j + 1) % size
                    references.append({"$ref": f"#/definitions/Component{ref_target}"})

                schema["definitions"][f"Component{i}"] = {
                    "type": "object",
                    "properties": {
                        "id": {"type": "string"},
                        "children": {
                            "type": "array",
                            "items": {"oneOf": references}
                        },
                        "parent": {
                            "$ref": f"#/definitions/Component{(i - 1) % size}"
                        }
                    }
                }

            return schema

    def benchmark_resolution(self, schema: Dict, max_depth: int = 20) -> Tuple[Dict, SimpleMetrics]:
        """–ë–µ–Ω—á–º–∞—Ä–∫ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è —Å—Ö–µ–º—ã"""

        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        test_file = self.base_path / "temp_test_schema.json"
        with open(test_file, 'w', encoding='utf-8') as f:
            json.dump(schema, f)

        profiler = SimpleProfiler()
        profiler.start_profiling()

        try:
            resolver = SDUIFinalResolver(str(self.base_path))
            result = resolver.resolve_file(str(test_file), max_depth=max_depth)
        except Exception as e:
            result = {"error": str(e), "traceback": str(e)}
        finally:
            profiler.stop_profiling()
            test_file.unlink()

        return result, profiler.metrics

    def test_scalability(self) -> Dict:
        """–¢–µ—Å—Ç –º–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç–∏"""
        print("üìà Testing scalability...")

        results = {}
        component_counts = [5, 10, 20, 50, 100]

        for count in component_counts:
            print(f"  Testing {count} components...")

            schema = self.create_test_schema("medium", count)
            result, metrics = self.benchmark_resolution(schema)

            results[f"components_{count}"] = {
                "execution_time": metrics.execution_time,
                "memory_peak_mb": metrics.memory_peak / 1024 / 1024 if metrics.memory_peak else 0,
                "success": isinstance(result, dict) and "_metadata" in result,
                "total_resolutions": result.get("_metadata", {}).get("total_resolutions", 0) if isinstance(result, dict) else 0,
                "total_stubs": result.get("_metadata", {}).get("total_stubs", 0) if isinstance(result, dict) else 0
            }

        return results

    def test_depth_performance(self) -> Dict:
        """–¢–µ—Å—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –≥–ª—É–±–∏–Ω–µ"""
        print("üîç Testing depth performance...")

        results = {}
        depths = [5, 10, 20, 30, 50]

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ö–µ–º—É —Å—Ä–µ–¥–Ω–µ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        schema = self.create_test_schema("complex", 20)

        for depth in depths:
            print(f"  Testing max_depth={depth}...")

            result, metrics = self.benchmark_resolution(schema, depth)

            results[f"depth_{depth}"] = {
                "execution_time": metrics.execution_time,
                "memory_peak_mb": metrics.memory_peak / 1024 / 1024 if metrics.memory_peak else 0,
                "success": isinstance(result, dict) and "_metadata" in result,
                "total_resolutions": result.get("_metadata", {}).get("total_resolutions", 0) if isinstance(result, dict) else 0,
                "total_stubs": result.get("_metadata", {}).get("total_stubs", 0) if isinstance(result, dict) else 0
            }

        return results

    def test_complexity_types(self) -> Dict:
        """–¢–µ—Å—Ç —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""
        print("üßÆ Testing complexity types...")

        results = {}
        complexities = ["simple", "medium", "complex"]

        for complexity in complexities:
            print(f"  Testing {complexity} schema...")

            schema = self.create_test_schema(complexity, 20)
            result, metrics = self.benchmark_resolution(schema)

            results[complexity] = {
                "execution_time": metrics.execution_time,
                "memory_peak_mb": metrics.memory_peak / 1024 / 1024 if metrics.memory_peak else 0,
                "success": isinstance(result, dict) and "_metadata" in result,
                "schema_size_kb": len(json.dumps(schema)) / 1024,
                "total_resolutions": result.get("_metadata", {}).get("total_resolutions", 0) if isinstance(result, dict) else 0
            }

        return results

    def profile_with_cprofile(self) -> str:
        """–î–µ—Ç–∞–ª—å–Ω–æ–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ"""
        print("üî¨ Running cProfile analysis...")

        schema = self.create_test_schema("medium", 15)
        test_file = self.base_path / "temp_profile_schema.json"

        with open(test_file, 'w') as f:
            json.dump(schema, f)

        try:
            pr = cProfile.Profile()
            resolver = SDUIFinalResolver(str(self.base_path))

            pr.enable()
            result = resolver.resolve_file(str(test_file), max_depth=20)
            pr.disable()

            # –°–æ–∑–¥–∞–µ–º –æ—Ç—á–µ—Ç
            s = io.StringIO()
            ps = pstats.Stats(pr, stream=s)
            ps.sort_stats('cumulative')
            ps.print_stats(15)  # –¢–æ–ø 15 —Ñ—É–Ω–∫—Ü–∏–π

            return s.getvalue()

        finally:
            test_file.unlink()

    def analyze_algorithmic_complexity(self, scalability_results: Dict) -> Dict:
        """–ê–Ω–∞–ª–∏–∑ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏"""

        complexity_analysis = {}

        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ
        components = []
        times = []

        for key, data in scalability_results.items():
            if key.startswith("components_"):
                count = int(key.split("_")[1])
                components.append(count)
                times.append(data["execution_time"])

        if len(components) < 2:
            return {"error": "Insufficient data for complexity analysis"}

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤
        paired = list(zip(components, times))
        paired.sort()
        components, times = zip(*paired)

        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Ç–Ω–æ—à–µ–Ω–∏—è —Ä–æ—Å—Ç–∞
        growth_ratios = []
        for i in range(1, len(times)):
            if times[i-1] > 0:
                ratio = times[i] / times[i-1]
                component_ratio = components[i] / components[i-1]
                growth_ratios.append(ratio / component_ratio)

        avg_growth = sum(growth_ratios) / len(growth_ratios) if growth_ratios else 1.0

        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        if avg_growth < 1.2:
            complexity_class = "O(n) - Linear"
        elif avg_growth < 2.0:
            complexity_class = "O(n log n) - Linearithmic"
        elif avg_growth < 3.0:
            complexity_class = "O(n¬≤) - Quadratic"
        else:
            complexity_class = "O(n¬≥+) - Polynomial or worse"

        complexity_analysis = {
            "estimated_complexity": complexity_class,
            "average_growth_factor": avg_growth,
            "growth_ratios": growth_ratios,
            "data_points": list(zip(components, times))
        }

        return complexity_analysis

    def identify_bottlenecks(self, all_results: Dict) -> List[Dict]:
        """–ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç"""

        bottlenecks = []

        # –ê–Ω–∞–ª–∏–∑ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        scalability = all_results.get("scalability", {})
        if scalability:
            max_time = max(data["execution_time"] for data in scalability.values())
            if max_time > 1.0:  # –ë–æ–ª–µ–µ 1 —Å–µ–∫—É–Ω–¥—ã
                bottlenecks.append({
                    "type": "execution_time",
                    "severity": "high" if max_time > 5.0 else "medium",
                    "description": f"Maximum execution time: {max_time:.2f}s",
                    "recommendation": "Consider caching, memoization, or algorithm optimization"
                })

        # –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏
        max_memory = 0
        for result_set in all_results.values():
            if isinstance(result_set, dict):
                for data in result_set.values():
                    if isinstance(data, dict) and "memory_peak_mb" in data:
                        max_memory = max(max_memory, data["memory_peak_mb"])

        if max_memory > 100:  # –ë–æ–ª–µ–µ 100MB
            bottlenecks.append({
                "type": "memory_usage",
                "severity": "high" if max_memory > 500 else "medium",
                "description": f"Peak memory usage: {max_memory:.1f}MB",
                "recommendation": "Implement memory pooling or reduce deep copying"
            })

        # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è stub'–æ–≤
        depth_results = all_results.get("depth_performance", {})
        if depth_results:
            for depth_key, data in depth_results.items():
                if data.get("total_resolutions", 0) > 0:
                    stub_ratio = data.get("total_stubs", 0) / data["total_resolutions"]
                    if stub_ratio > 0.5:  # –ë–æ–ª–µ–µ 50% –∑–∞–≥–ª—É—à–µ–∫
                        bottlenecks.append({
                            "type": "high_stub_ratio",
                            "severity": "medium",
                            "description": f"High stub ratio ({stub_ratio:.1%}) at {depth_key}",
                            "recommendation": "Increase max_depth or optimize component tracking"
                        })

        return bottlenecks

    def run_comprehensive_analysis(self) -> Dict:
        """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        print("üöÄ Starting comprehensive performance analysis...")

        results = {
            "scalability": self.test_scalability(),
            "depth_performance": self.test_depth_performance(),
            "complexity_types": self.test_complexity_types(),
            "detailed_profile": self.profile_with_cprofile()
        }

        # –ê–Ω–∞–ª–∏–∑ –∞–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–æ–π —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
        results["algorithmic_complexity"] = self.analyze_algorithmic_complexity(results["scalability"])

        # –ò–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è —É–∑–∫–∏—Ö –º–µ—Å—Ç
        results["bottlenecks"] = self.identify_bottlenecks(results)

        return results

def generate_performance_report(analysis_results: Dict) -> str:
    """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""

    report = []
    report.append("=" * 80)
    report.append("üìä SDUI RESOLVER PERFORMANCE ANALYSIS REPORT")
    report.append("=" * 80)
    report.append("")

    # 1. –û–±–∑–æ—Ä –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    report.append("üîç 1. PERFORMANCE OVERVIEW")
    report.append("-" * 40)

    complexity_types = analysis_results.get("complexity_types", {})
    if complexity_types:
        for complexity, data in complexity_types.items():
            report.append(f"{complexity.upper():8}: {data['execution_time']:.3f}s | {data['memory_peak_mb']:.1f}MB | {data['total_resolutions']} resolutions")

    report.append("")

    # 2. –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º–æ—Å—Ç—å
    report.append("üìà 2. SCALABILITY ANALYSIS")
    report.append("-" * 40)

    scalability = analysis_results.get("scalability", {})
    if scalability:
        report.append("Components | Time (s) | Memory (MB) | Resolutions | Growth")
        report.append("-" * 55)

        prev_time = None
        for key in sorted(scalability.keys(), key=lambda x: int(x.split("_")[1])):
            data = scalability[key]
            components = key.split("_")[1]
            time_val = data["execution_time"]
            memory_val = data["memory_peak_mb"]
            resolutions = data["total_resolutions"]

            growth = ""
            if prev_time and prev_time > 0:
                ratio = time_val / prev_time
                growth = f"x{ratio:.1f}"

            report.append(f"{components:>9} | {time_val:>7.3f} | {memory_val:>10.1f} | {resolutions:>11} | {growth}")
            prev_time = time_val

    report.append("")

    # 3. –ê–ª–≥–æ—Ä–∏—Ç–º–∏—á–µ—Å–∫–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
    report.append("üßÆ 3. ALGORITHMIC COMPLEXITY")
    report.append("-" * 40)

    complexity = analysis_results.get("algorithmic_complexity", {})
    if complexity and "estimated_complexity" in complexity:
        report.append(f"Estimated complexity: {complexity['estimated_complexity']}")
        report.append(f"Average growth factor: {complexity['average_growth_factor']:.2f}")

        if complexity["average_growth_factor"] > 2.0:
            report.append("‚ö†Ô∏è  WARNING: Algorithm shows poor scalability")
        elif complexity["average_growth_factor"] > 1.5:
            report.append("‚ö†Ô∏è  CAUTION: Algorithm may not scale well for large inputs")
        else:
            report.append("‚úÖ Algorithm shows good scalability characteristics")

    report.append("")

    # 4. –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ –≥–ª—É–±–∏–Ω–µ
    report.append("üîç 4. DEPTH PERFORMANCE")
    report.append("-" * 40)

    depth_perf = analysis_results.get("depth_performance", {})
    if depth_perf:
        report.append("Max Depth | Time (s) | Memory (MB) | Stubs/Total")
        report.append("-" * 45)

        for key in sorted(depth_perf.keys(), key=lambda x: int(x.split("_")[1])):
            data = depth_perf[key]
            depth = key.split("_")[1]
            time_val = data["execution_time"]
            memory_val = data["memory_peak_mb"]

            stubs = data.get("total_stubs", 0)
            total = data.get("total_resolutions", 1)
            stub_ratio = stubs / total if total > 0 else 0

            report.append(f"{depth:>9} | {time_val:>7.3f} | {memory_val:>10.1f} | {stub_ratio:>10.1%}")

    report.append("")

    # 5. –£–∑–∫–∏–µ –º–µ—Å—Ç–∞
    report.append("üéØ 5. PERFORMANCE BOTTLENECKS")
    report.append("-" * 40)

    bottlenecks = analysis_results.get("bottlenecks", [])
    if bottlenecks:
        for bottleneck in bottlenecks:
            severity_icon = "üî¥" if bottleneck["severity"] == "high" else "üü°"
            report.append(f"{severity_icon} {bottleneck['type'].upper()}: {bottleneck['description']}")
            report.append(f"   üí° {bottleneck['recommendation']}")
    else:
        report.append("‚úÖ No significant bottlenecks detected")

    report.append("")

    # 6. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    report.append("üí° 6. OPTIMIZATION RECOMMENDATIONS")
    report.append("-" * 40)

    recommendations = []

    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    if complexity and complexity.get("average_growth_factor", 1) > 2.0:
        recommendations.append("üîß ALGORITHM: Implement caching for resolved components to reduce redundant computations")

    if any(data.get("memory_peak_mb", 0) > 100 for result_set in analysis_results.values()
           if isinstance(result_set, dict) for data in result_set.values() if isinstance(data, dict)):
        recommendations.append("üîß MEMORY: Replace deepcopy with shallow copying where possible")

    # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recommendations.extend([
        "üîß CACHING: Implement file-level caching to avoid repeated JSON parsing",
        "üîß LAZY LOADING: Load external schemas only when needed",
        "üîß COMPONENT TRACKING: Optimize component deduplication algorithm",
        "üîß MEMORY POOLING: Reuse objects instead of creating new ones",
        "üîß PARALLEL PROCESSING: Process independent branches concurrently"
    ])

    for rec in recommendations:
        report.append(rec)

    report.append("")
    report.append("=" * 80)

    return "\n".join(report)

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    import argparse

    parser = argparse.ArgumentParser(description="SDUI Resolver Performance Analyzer")
    parser.add_argument("--script", default="/Users/username/Scripts/Python/sdui-resolver-final.py",
                       help="Path to sdui-resolver-final.py")
    parser.add_argument("--output", help="Output file for the report")
    parser.add_argument("--verbose", action="store_true", help="Show detailed cProfile output")

    args = parser.parse_args()

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Å–∫—Ä–∏–ø—Ç–∞
    script_path = Path(args.script)
    if not script_path.exists():
        print(f"‚ùå Script not found: {script_path}")
        return

    # –°–æ–∑–¥–∞–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä
    analyzer = SDUIPerformanceAnalyzer(str(script_path))

    # –ó–∞–ø—É—Å–∫–∞–µ–º –∞–Ω–∞–ª–∏–∑
    print("üöÄ Starting SDUI Resolver Performance Analysis...")
    analysis_results = analyzer.run_comprehensive_analysis()

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
    report = generate_performance_report(analysis_results)

    # –í—ã–≤–æ–¥–∏–º –æ—Ç—á–µ—Ç
    if args.output:
        with open(args.output, 'w', encoding='utf-8') as f:
            f.write(report)
        print(f"üìÑ Report saved to: {args.output}")
    else:
        print(report)

    # –î–µ—Ç–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å –µ—Å–ª–∏ –Ω—É–∂–µ–Ω
    if args.verbose:
        print("\n" + "=" * 80)
        print("üî¨ DETAILED CPROFILE ANALYSIS")
        print("=" * 80)
        print(analysis_results.get("detailed_profile", "No detailed profile available"))

if __name__ == "__main__":
    main()